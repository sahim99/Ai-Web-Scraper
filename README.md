# ğŸ” AI Web Scraper

A modern, AI-powered web scraping tool that extracts specific information from any website using intelligent parsing.

## âœ¨ Features

- **ğŸŒ Smart Web Scraping** - Fast, headless browser scraping
- **ğŸ¤– AI-Powered Parsing** - Extract specific data using local LLM (Ollama)
- **ğŸ¨ Modern UI** - Beautiful dark theme with gradient accents
- **âš¡ Ultra-Fast** - Optimized for speed and efficiency
- **ğŸ“Š Structured Output** - Clean, formatted results
- **ğŸ› ï¸ Easy Setup** - Simple installation and configuration

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.8+** installed
2. **Ollama** installed and running locally
3. **Chrome/Chromium** browser installed

### Installation

1. **Clone or download** this project
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Test installation:**
   ```bash
   python test_imports.py
   ```

4. **Start Ollama** (if not running):
   ```bash
   ollama serve
   ```

5. **Pull the AI model:**
   ```bash
   ollama pull llama3
   ```

### Running the App

```bash
streamlit run main.py
```

The app will open at `http://localhost:8501`

## ğŸ“– Usage Guide

### 1. Enter Website URL
- Paste any website URL you want to scrape
- Click "ğŸ•·ï¸ Scrape Website"

### 2. Describe What to Extract
- In the parsing section, describe what information you want
- Examples:
  - "Extract all project names and technologies"
  - "Get all product prices and names"
  - "Find contact information and addresses"

### 3. Parse Content
- Click "ğŸš€ Parse Content"
- AI will extract the requested information
- Results appear in a clean, formatted table

## âš™ï¸ Settings

### Sidebar Options:
- **Headless Mode** - Faster scraping (recommended ON)
- **Page Load Wait Time** - How long to wait for page loading
- **AI Model** - Choose between llama3, gpt-4, mistral
- **Max Chunk Size** - Size of content chunks for processing

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file for custom settings:
```env
OLLAMA_BASE_URL=http://localhost:11434
CHROME_DRIVER_PATH=./chromedriver.exe
```

### Model Configuration
The AI model can be configured in `parse.py`:
```python
model = OllamaLLM(
    model="llama3",
    temperature=0.0,
    max_tokens=80,
    timeout=8
)
```

## ğŸ› ï¸ Troubleshooting

### Common Issues:

1. **"Chrome driver not found"**
   - Download chromedriver.exe for your Chrome version
   - Place it in the project root directory

2. **"Ollama connection failed"**
   - Ensure Ollama is running: `ollama serve`
   - Check if model is pulled: `ollama list`

3. **"Import errors"**
   - Run: `pip install -r requirements.txt`
   - Test with: `python test_imports.py`

4. **"Slow parsing"**
   - Reduce chunk size in settings
   - Use smaller content sections
   - Check Ollama model performance

### Performance Tips:

- âœ… Keep headless mode ON
- âœ… Use smaller chunk sizes for better parsing
- âœ… Be specific in extraction requests
- âœ… Try different AI models for better results

## ğŸ“ Project Structure

```
AI Web Scraper/
â”œâ”€â”€ main.py              # Main Streamlit application
â”œâ”€â”€ scrape.py            # Web scraping functions
â”œâ”€â”€ parse.py             # AI parsing functions
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ test_imports.py     # Dependency testing
â”œâ”€â”€ chromedriver.exe    # Chrome driver
â””â”€â”€ README.md           # This file
```

## ğŸ”„ Updates

### Recent Improvements:
- âœ… **Ultra-fast parsing** - Single chunk processing
- âœ… **Structured data** - Preserves HTML structure
- âœ… **Clean output** - No verbose explanations
- âœ… **Better error handling** - Comprehensive fallbacks
- âœ… **Modern UI** - Dark theme with gradients

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ†˜ Support

If you encounter issues:
1. Check the troubleshooting section
2. Run `python test_imports.py`
3. Ensure all dependencies are installed
4. Verify Ollama is running

---

**Made with â¤ï¸ using Streamlit | AI Web Scraper v1.0** 